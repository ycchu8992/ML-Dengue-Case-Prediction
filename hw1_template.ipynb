{"cells":[{"cell_type":"markdown","metadata":{"id":"X_Te27fi-0pP"},"source":["# **HW1: Regression** \n","In *assignment 1*, you need to finish:\n","\n","1.  Basic Part: Implement the regression model to predict the number of dengue cases\n","\n","\n","> *   Step 1: Split Data\n","> *   Step 2: Preprocess Data\n","> *   Step 3: Implement Regression\n","> *   Step 4: Make Prediction\n","> *   Step 5: Train Model and Generate Result\n","\n","2.  Advanced Part: Implementing a regression model to predict the number of dengue cases in a different way than the basic part"]},{"cell_type":"markdown","metadata":{"id":"_wDdnos-4uUv"},"source":["# 1. Basic Part (60%)\n","In the first part, you need to implement the regression to predict the number of dengue cases\n","\n","Please save the prediction result in a csv file **hw1_basic.csv**\n"]},{"cell_type":"markdown","metadata":{"id":"RzCR7vk9BFkf"},"source":["## Import Packages\n","\n","> Note: You **cannot** import any other package in the basic part"]},{"cell_type":"code","execution_count":112,"metadata":{"id":"HL5XjqFf4wSj"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import csv\n","import math\n","import random"]},{"cell_type":"markdown","metadata":{"id":"jnWjrzi0dMPz"},"source":["## Global attributes\n","Define the global attributes"]},{"cell_type":"code","execution_count":113,"metadata":{"id":"EWLDPOlHBbcK"},"outputs":[],"source":["input_dataroot = 'hw1_basic_input.csv' # Input file named as 'hw1_basic_input.csv'\n","output_dataroot = 'hw1_basic.csv' # Output file will be named as 'hw1_basic.csv'\n","\n","input_datalist =  [] # Initial datalist, saved as numpy array\n","output_datalist =  [] # Your prediction, should be 10 * 4 matrix and saved as numpy array\n","             # The format of each row should be ['epiweek', 'CityA', 'CityB', 'CityC']"]},{"cell_type":"markdown","metadata":{"id":"PsFC-cvqIcYK"},"source":["You can add your own global attributes here\n"]},{"cell_type":"code","execution_count":114,"metadata":{"id":"OUbS2BEgcut6"},"outputs":[],"source":["processed_dataset_list = [[],[],[]]\n","train_dataset_list = [[],[],[]]\n","valid_dataset_list = [[],[],[]]\n","unknown_dataset_list = [[],[],[]]\n","predict_dataset_list = [[],[],[]]\n","phi_matrix = [[],[],[]]\n","city_w = [[],[],[]]\n"]},{"cell_type":"markdown","metadata":{"id":"rUoRFoQjBW5S"},"source":["## Load the Input File\n","First, load the basic input file **hw1_basic_input.csv**\n","\n","Input data would be stored in *input_datalist*"]},{"cell_type":"code","execution_count":115,"metadata":{"id":"dekR1KnqBtI6"},"outputs":[],"source":["# Read input csv to datalist\n","with open(input_dataroot, newline='') as csvfile:\n","  input_datalist = np.array(list(csv.reader(csvfile)))"]},{"cell_type":"markdown","metadata":{"id":"6kYPuikLCFx4"},"source":["## Implement the Regression Model\n","\n","> Note: It is recommended to use the functions we defined, you can also define your own functions\n"]},{"cell_type":"markdown","metadata":{"id":"u-3Qln4aNgVy"},"source":["### Step 1: Preprocess Data\n","Handle the unreasonable data\n","> Hint: Outlier and missing data can be handled by removing the data or adding the values with the help of statistics  "]},{"cell_type":"code","execution_count":116,"metadata":{"id":"XXvW1n_5NkQ5"},"outputs":[],"source":["def PreprocessData():\n"," \n","    global input_datalist\n","\n","    input_datalist = np.delete(input_datalist,0,axis=0)\n","\n","    for i in [4, 5, 6]:\n","        B = np.insert(np.delete(input_datalist[:,i],-1,axis=0), 0, np.array(['']), axis=0)\n","        input_datalist = np.c_[input_datalist, B.transpose()]\n","\n","    for i in [1,2,3]:\n","\n","        global processed_dataset_list\n","        \n","        #detect empty input in column with index i in the dataset(false means empty in mask)\n","        mask = np.isin(input_datalist[:,i], [''], invert = True)\n","\n","        #remove rows with empty input in dataset\n","        dataset_remove_empty = input_datalist[mask]\n","\n","        #change the data type in dataset, and calculate the absolute value of each element's Z score\n","        temp = dataset_remove_empty[:,i].astype(np.double)\n","        temp_Z_score_abs = np.absolute((temp - np.average(temp))/np.std(temp))\n","\n","        #change the value to integer which help us to identify outliers\n","        mask_t = np.isin(temp_Z_score_abs.astype(np.int64),[0], invert = False)\n","            \n","        dataset_remove_empty = dataset_remove_empty[mask_t]\n","\n","        #detect empty input in column with index i+6(city's cases in yesterday) in the dataset(false means empty in mask)\n","        mask = np.isin(dataset_remove_empty[:,i+6], [''], invert = True)\n","\n","        dataset_remove_empty = dataset_remove_empty[mask]\n","        dataset_remove_empty = dataset_remove_empty.astype(np.double)\n","            \n","        #store only the temperature, data and number of cases in the list\n","        processed_dataset_list[i-1] = dataset_remove_empty.transpose()[np.array([0,i,i+3,i+6])].transpose()"]},{"cell_type":"markdown","metadata":{"id":"jWwdx06JNEYs"},"source":["### Step 2: Split Data\n","Split data in *input_datalist* into training dataset and validation dataset \n","\n"]},{"cell_type":"code","execution_count":117,"metadata":{"id":"USDciENcB-5F"},"outputs":[],"source":["def SplitData():\n","    global train_dataset_list\n","    global valid_dataset_list\n","\n","    for i in range(3):\n","        #numbers of rows without datas that we want to predict(10)\n","        data_row = np.size(processed_dataset_list[i],0) - 10\n","\n","        #number of dataset for training\n","        num_train = int(data_row * 0.7)\n","\n","        #number of dataset for validation\n","        num_valid = data_row - num_train\n","           \n","        train_dataset_list[i] = processed_dataset_list[i][0:num_train]\n","        valid_dataset_list[i] = processed_dataset_list[i][num_train:num_train+num_valid]\n","        unknown_dataset_list[i] = processed_dataset_list[i][num_train+num_valid:]\n","        "]},{"cell_type":"markdown","metadata":{"id":"yDLpJmQUN3V6"},"source":["### Step 3: Implement Regression\n","> Hint: You can use Matrix Inversion, or Gradient Descent to finish this part\n","\n","\n"]},{"cell_type":"code","execution_count":118,"metadata":{},"outputs":[],"source":["def phi_function(x, m):\n","    if m == 0:\n","        return x\n","    elif m==1:\n","        return x\n","    elif m==2:\n","        return x\n","    else:\n","        return x"]},{"cell_type":"code","execution_count":119,"metadata":{"id":"Tx9n1_23N8C0"},"outputs":[],"source":["\n","def Regression(city):\n","    #y = W0 + w1 * phi(temp) + w2 * phi(yester_cases) + error\n","    #processed_dataset_list[city_name][data_list][temp]\n","    \n","    M = city\n","\n","    row = np.size(train_dataset_list[M],0)\n","    for i in range(row):\n","        a = train_dataset_list[M][i][1]\n","        b = train_dataset_list[M][i][3]\n","        t = np.array([1, phi_function(a, M), phi_function(b, M)])\n","        if i==0:\n","            phi_matrix[M] = t\n","        else:\n","            phi_matrix[M] = np.r_[phi_matrix[M], t]\n","\n","    phi_matrix[M] = phi_matrix[M].reshape(row, 3)\n","    \n","    w = np.linalg.inv(phi_matrix[M].T.dot(phi_matrix[M])).dot(phi_matrix[M].T).dot(train_dataset_list[M][:,2].reshape(row, 1))\n","\n","    return w\n"]},{"cell_type":"markdown","metadata":{"id":"2NxRNFwyN8xd"},"source":["### Step 4: Make Prediction\n","Make prediction of testing dataset and store the value in *output_datalist*"]},{"cell_type":"code","execution_count":120,"metadata":{"id":"EKlDIC2-N_lk"},"outputs":[],"source":["def MakePrediction(city):\n","\n","    M = city\n","    \n","    global city_w\n","\n","    row = np.size(valid_dataset_list[M],0)\n","\n","    predict_dataset_list[M] = np.arange(row)\n","\n","    MAPE = 0\n","\n","    for i in range(row):\n","\n","        a = valid_dataset_list[M][i][1]\n","        \n","        if i==0:\n","        \n","            b = valid_dataset_list[M][i][3]\n","        \n","        else:\n","        \n","            b = predict_dataset_list[M][i-1]\n","\n","        predict_dataset_list[M][i] = int(city_w[M].T.dot([1, a, b]))\n","\n","        y1 = valid_dataset_list[M][i][2] \n","        \n","        y2 = predict_dataset_list[M][i]\n","\n","        MAPE += np.absolute((y1-y2)/y1)\n","\n","    print(str(int(MAPE*1000/row)/10) + \"%\" )\n","\n","\n","\n","\n","\n","    \n","    "]},{"cell_type":"markdown","metadata":{"id":"cCd0Z6izOCwq"},"source":["### Step 5: Train Model and Generate Result\n","\n","> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n","* If your regression model is *3x^2 + 2x^1 + 1*, your output would be: \n","```\n","3 2 1\n","```\n","\n","\n","\n"]},{"cell_type":"code","execution_count":121,"metadata":{"id":"iCL92EPKOFIn"},"outputs":[{"name":"stdout","output_type":"stream","text":["33.6%\n","32.3%\n","72.6%\n"]}],"source":["PreprocessData()\n","\n","SplitData()\n","\n","for i in range(3):\n","    city_w[i] = Regression(i)\n","    MakePrediction(i)\n"]},{"cell_type":"markdown","metadata":{"id":"J8Jhd8wAOk3D"},"source":["## Write the Output File\n","Write the prediction to output csv\n","> Format: 'epiweek', 'CityA', 'CityB', 'CityC'"]},{"cell_type":"code","execution_count":122,"metadata":{"id":"tYQVYLlKOtDB"},"outputs":[],"source":["with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n","  writer = csv.writer(csvfile)\n","  for row in output_datalist:\n","    writer.writerow(row)"]},{"cell_type":"markdown","metadata":{"id":"rx4408qg4xMQ"},"source":["# 2. Advanced Part (35%)\n","In the second part, you need to implement the regression in a different way than the basic part to help your predictions for the number of dengue cases\n","\n","We provide you with two files **hw1_advanced_input1.csv** and **hw1_advanced_input2.csv** that can help you in this part\n","\n","Please save the prediction result in a csv file **hw1_advanced.csv** \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DaZCe19m41g1"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"EtgCJU7FPeJL"},"source":["# Report *(5%)*\n","\n","Report should be submitted as a pdf file **hw1_report.pdf**\n","\n","*   Briefly describe the difficulty you encountered \n","*   Summarize your work and your reflections \n","*   No more than one page\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hlEE53_MPf4W"},"source":["# Save the Code File\n","Please save your code and submit it as an ipynb file! (**hw1.ipynb**)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"}}},"nbformat":4,"nbformat_minor":0}
